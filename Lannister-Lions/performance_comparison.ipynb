{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71bf7460-dcc1-4f5e-88aa-cd9272f5b568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (4.31.0)\n",
      "Requirement already satisfied: einops in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (0.6.1)\n",
      "Requirement already satisfied: accelerate in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: langchain in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (0.0.266)\n",
      "Requirement already satisfied: bitsandbytes in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (0.40.2)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pypdf in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (3.17.2)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: filelock in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: psutil in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (0.0.70)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (2.8.8)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Downloading torchvision-0.16.2-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from sentence_transformers) (1.10.1)\n",
      "Collecting nltk (from sentence_transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from sentence_transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.7.4.3 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from pypdf) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
      "Requirement already satisfied: sympy in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (58.1.0)\n",
      "Requirement already satisfied: wheel in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.42.0)\n",
      "Requirement already satisfied: cmake in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.9)\n",
      "Requirement already satisfied: lit in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.6)\n",
      "Requirement already satisfied: click in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Collecting joblib (from nltk->sentence_transformers)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Downloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch>=1.10.0->accelerate)\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.2-cp39-cp39-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125936 sha256=0d0a2329d992b71ed4ede98489a6a47568a348a9589f4976ff391bfe04e063c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentencepiece, triton, threadpoolctl, python-dotenv, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, joblib, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, nvidia-cusolver-cu12, torch, torchvision, sentence_transformers\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "Successfully installed joblib-1.3.2 nltk-3.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 python-dotenv-1.0.0 scikit-learn-1.3.2 sentence_transformers-2.2.2 sentencepiece-0.1.99 threadpoolctl-3.2.0 torch-2.1.2 torchvision-0.16.2 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers einops accelerate langchain bitsandbytes sentence_transformers pypdf python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a19a20-59a2-4e69-ac5f-1dc01c7e27d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing-extensions==4.5.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic 2.5.2 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.14.5 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install typing-extensions==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d5e844-3dfa-4e96-b397-c58209a185b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2023.12.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/hackathon/oneapi-devsummit-sea-2023/itex_cpu/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc27ea92-53ca-4f59-a6b0-828fa42fd843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.8.5\n",
      "  Downloading llama_index-0.8.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tiktoken (from llama-index==0.8.5)\n",
      "  Downloading tiktoken-0.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting dataclasses-json (from llama-index==0.8.5)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<=0.0.266,>=0.0.262 (from llama-index==0.8.5)\n",
      "  Downloading langchain-0.0.266-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting sqlalchemy>=2.0.15 (from llama-index==0.8.5)\n",
      "  Downloading SQLAlchemy-2.0.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: numpy in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from llama-index==0.8.5) (1.23.5)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index==0.8.5)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting openai>=0.26.4 (from llama-index==0.8.5)\n",
      "  Downloading openai-1.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pandas in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from llama-index==0.8.5) (2.1.4)\n",
      "Collecting urllib3<2 (from llama-index==0.8.5)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m892.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from llama-index==0.8.5) (2023.10.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index==0.8.5)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from llama-index==0.8.5) (4.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from llama-index==0.8.5) (4.12.2)\n",
      "Requirement already satisfied: nest-asyncio in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from llama-index==0.8.5) (1.5.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (4.0.3)\n",
      "Collecting dataclasses-json (from llama-index==0.8.5)\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5)\n",
      "  Downloading langsmith-0.0.70-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5)\n",
      "  Downloading numexpr-2.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5)\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<2,>=1 (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5)\n",
      "  Downloading pydantic-1.10.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (2.31.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index==0.8.5)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from openai>=0.26.4->llama-index==0.8.5) (4.1.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=0.26.4->llama-index==0.8.5)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=0.26.4->llama-index==0.8.5)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: sniffio in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from openai>=0.26.4->llama-index==0.8.5) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from openai>=0.26.4->llama-index==0.8.5) (4.66.1)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=2.0.15->llama-index==0.8.5)\n",
      "  Downloading greenlet-3.0.2-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index==0.8.5)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from beautifulsoup4->llama-index==0.8.5) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from pandas->llama-index==0.8.5) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from pandas->llama-index==0.8.5) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from pandas->llama-index==0.8.5) (2023.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from tiktoken->llama-index==0.8.5) (2023.10.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=0.26.4->llama-index==0.8.5) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=0.26.4->llama-index==0.8.5) (1.2.0)\n",
      "Requirement already satisfied: certifi in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>=0.26.4->llama-index==0.8.5) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=0.26.4->llama-index==0.8.5)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.26.4->llama-index==0.8.5)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index==0.8.5) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index==0.8.5) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->llama-index==0.8.5) (3.3.2)\n",
      "Downloading llama_index-0.8.5-py3-none-any.whl (678 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.4/678.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.0.266-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Downloading openai-1.4.0-py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.9/221.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.2-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (610 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.9/610.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.70-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m822.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m928.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numexpr-2.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.3/374.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-1.10.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, tenacity, pydantic, numexpr, mypy-extensions, marshmallow, h11, greenlet, distro, typing-inspect, sqlalchemy, openapi-schema-pydantic, httpcore, tiktoken, langsmith, httpx, dataclasses-json, openai, langchain, llama-index\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "Successfully installed dataclasses-json-0.5.14 distro-1.8.0 greenlet-3.0.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 langchain-0.0.266 langsmith-0.0.70 llama-index-0.8.5 marshmallow-3.20.1 mypy-extensions-1.0.0 numexpr-2.8.8 openai-1.4.0 openapi-schema-pydantic-1.2.4 pydantic-1.10.13 sqlalchemy-2.0.23 tenacity-8.2.3 tiktoken-0.5.2 typing-inspect-0.9.0 urllib3-1.26.18\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f887b16-31dc-41ba-9832-99034f0d58a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-14.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /root/hackathon/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from pyarrow) (1.23.5)\n",
      "Downloading pyarrow-14.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-14.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d5c5b0-c537-4259-90a4-e15c601d54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting intel_extension_for_pytorch\n",
      "  Downloading intel_extension_for_pytorch-2.1.100-cp39-cp39-manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from intel_extension_for_pytorch) (5.9.6)\n",
      "Requirement already satisfied: numpy in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from intel_extension_for_pytorch) (1.23.5)\n",
      "Requirement already satisfied: packaging in /root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages (from intel_extension_for_pytorch) (23.2)\n",
      "Downloading intel_extension_for_pytorch-2.1.100-cp39-cp39-manylinux2014_x86_64.whl (51.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: intel_extension_for_pytorch\n",
      "Successfully installed intel_extension_for_pytorch-2.1.100\n"
     ]
    }
   ],
   "source": [
    "!pip install intel_extension_for_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fdb329-75dc-4fc3-b369-576f2438d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 18:41:36.604241: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-15 18:42:04,289 - numexpr.utils - INFO - Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-12-15 18:42:04,292 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "!export NUMEXPR_MAX_THREADS=30\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "########INTEL########\n",
    "import intel_extension_for_pytorch as ipex\n",
    "#####################\n",
    "from pprint import pprint\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from llama_index import LangchainEmbedding\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab31122a-fae0-4a62-9ca0-7d93612e4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index import download_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a65f9e2-2ace-43d7-93a7-fbe7e6a58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFReader = download_loader(\"PDFReader\")\n",
    "loader = PDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94da6a6c-5d3c-4d8b-9188-ac73d9c42c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load_data(file=Path('../supreme-court-data/data/data/8356-2015___supremecourt__2015__8356__8356_2015_Judgement_12-Oct-2017.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc884f5-517b-4539-94ff-96c94e76c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a data extractor. Extract the exact data from given document. If no information is found, please reply 'No information found'\"\n",
    "# query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")\n",
    "query_wrapper_prompt = \"<|USER|>{query_str}<|ASSISTANT|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60345eae-f6bb-4c35-b966-db28c2407271",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window = 4096\n",
    "temperature = 0.1\n",
    "model_name = 'litelo/llama-2-case-whisper'\n",
    "tokenizer_model_name='meta-llama/Llama-2-7b-chat-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9e5237-8c44-42d3-a7ac-93d1794d4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.xpu.is_available():\n",
    "    seed = 88\n",
    "    random.seed(seed)\n",
    "    torch.xpu.manual_seed(seed)\n",
    "    torch.xpu.manual_seed_all(seed)\n",
    "\n",
    "def select_device(preferred_device=None):\n",
    "    \"\"\"\n",
    "    Selects the best available XPU device or the preferred device if specified.\n",
    "\n",
    "    Args:\n",
    "        preferred_device (str, optional): Preferred device string (e.g., \"cpu\", \"xpu\", \"xpu:0\", \"xpu:1\", etc.). If None, a random available XPU device will be selected or CPU if no XPU devices are available.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The selected device object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if preferred_device and preferred_device.startswith(\"cpu\"):\n",
    "            print(\"Using CPU.\")\n",
    "            return torch.device(\"cpu\")\n",
    "        if preferred_device and preferred_device.startswith(\"xpu\"):\n",
    "            if preferred_device == \"xpu\" or (\n",
    "                \":\" in preferred_device\n",
    "                and int(preferred_device.split(\":\")[1]) >= torch.xpu.device_count()\n",
    "            ):\n",
    "                preferred_device = (\n",
    "                    None  # Handle as if no preferred device was specified\n",
    "                )\n",
    "            else:\n",
    "                device = torch.device(preferred_device)\n",
    "                if device.type == \"xpu\" and device.index < torch.xpu.device_count():\n",
    "                    vram_used = torch.xpu.memory_allocated(device) / (\n",
    "                        1024**2\n",
    "                    )  # In MB\n",
    "                    print(\n",
    "                        f\"Using preferred device: {device}, VRAM used: {vram_used:.2f} MB\"\n",
    "                    )\n",
    "                    return device\n",
    "\n",
    "        if torch.xpu.is_available():\n",
    "            device_id = random.choice(\n",
    "                range(torch.xpu.device_count())\n",
    "            )  # Select a random available XPU device\n",
    "            device = torch.device(f\"xpu:{device_id}\")\n",
    "            vram_used = torch.xpu.memory_allocated(device) / (1024**2)  # In MB\n",
    "            print(f\"Selected device: {device}, VRAM used: {vram_used:.2f} MB\")\n",
    "            return device\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while selecting the device: {e}\")\n",
    "    print(\"No XPU devices available or preferred device not found. Using CPU.\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7c77ec-fe9b-4960-9ae6-a151b2b6f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No XPU devices available or preferred device not found. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "tokenizer = LlamaTokenizer.from_pretrained(tokenizer_model_name)\n",
    "selected_device = select_device(\"xpu\")\n",
    "# model_llm = (\n",
    "#     LlamaForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     # load_in_4bit=True,\n",
    "#     device_map='auto'\n",
    "# )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3688ad7c-c52f-4a21-8228-f31ee93bdb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 18:42:46,032 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2023-12-15 18:42:52,553 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7285f5-1f53-4b33-b6aa-296a6127c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f47b77-2e53-4d50-85f3-280065c2ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(intel_optimize):\n",
    "    if intel_optimize:\n",
    "        model_llm = (\n",
    "            LlamaForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                low_cpu_mem_usage=True,\n",
    "                torch_dtype=torch.bfloat16\n",
    "            )\n",
    "            .to(selected_device)\n",
    "            .eval()\n",
    "        )\n",
    "        if hasattr(ipex, \"optimize_transformers\"):\n",
    "            print(\"transformer optimize\")\n",
    "            try:\n",
    "                model_llm=ipex.optimize_transformers(model_llm, dtype=torch.bfloat16)\n",
    "            except:\n",
    "                model_llm=ipex.optimize(model_llm, dtype=torch.bfloat16)\n",
    "        else:\n",
    "            print(\"no-transformer optimize\")\n",
    "            model_llm=ipex.optimize(model_llm, dtype=torch.bfloat16)\n",
    "    else:\n",
    "        model_llm = (\n",
    "            LlamaForCausalLM.from_pretrained(\n",
    "                model_name\n",
    "            )\n",
    "            .to(selected_device)\n",
    "            .eval()\n",
    "        )\n",
    "    llm = HuggingFaceLLM(\n",
    "        context_window=context_window,\n",
    "        max_new_tokens=256,\n",
    "        generate_kwargs={\"temperature\":temperature,\"top_p\":0.5, \"do_sample\": False},\n",
    "        system_prompt= system_prompt,\n",
    "        query_wrapper_prompt = query_wrapper_prompt,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model_llm,\n",
    "        device_map='auto',\n",
    "        model_kwargs={\"temperature\":0.1, \"top_p\":0.5,\"use_auth_token\": True}\n",
    "    )\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        chunk_size=1024,\n",
    "        llm=llm,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    user_query=\"what is this case about\"\n",
    "    \n",
    "    response=query_engine.query(user_query)\n",
    "    print(\"Answer: \",response.response, \"\\n\")\n",
    "    time_taken = (time.time() - start_time)\n",
    "    print('\\n', 'time taken: ', \"--- %s seconds ---\" % time_taken)\n",
    "    model_llm = \"\"\n",
    "    return time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6c2950-27c0-42f4-ae21-de42801f5c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898137827eac4475bb65757fb67bc04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95176bd475b481fb91e4ca647eee6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f1daa8356442f794cd2bde81ff6fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/oneapi-devsummit-sea-2023/itex_xpu/lib/python3.9/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The case is about the classification of a perfumery compound as excisable or non-excisable. The assessee, M/s. Karnataka Soaps & Detergents Ltd, sold certain quantity of perfumery compound to M/s. Tibetan Handicrafts Centre Bylkuppe, Mysore District. The CESTAT held that the perfumery compound is excisable and classified it under Chapter Sub-Heading 3302.90. However, the Supreme Court allowed the appeals and set aside the orders dated 11.11.2010 passed by the CESTAT. The Court held that the perfumery compound is not excisable and classified it under Chapter Sub-Heading 3302.10. No costs. \n",
      "\n",
      "\n",
      " time taken:  --- 41.42193126678467 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# time_with_intel = execute_model(True)\n",
    "# 21.53885245323181\n",
    "time_without_intel = execute_model(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a49b15fc-de59-4e54-be5a-08ec2750bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_with_intel = 21.53885245323181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "694880f3-8ce2-4b5b-bef1-8950ba32ea5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 18:48:21,510 - matplotlib.font_manager - INFO - generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df2a4e5-dfad-4a74-bddb-6689c1b605e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_result = [(\"With ipex\", time_with_intel), (\"Without ipex\", time_without_intel)]\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.title(\"Performance Comparison: ipex optimization\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.bar([result[0] for result in benchmark_result], [result[1] for result in benchmark_result])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7309d6-b48a-425c-9531-321369ac8db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
